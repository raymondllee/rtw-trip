# Token Usage & Cost Tracking

Comprehensive token usage and cost tracking for cost research queries.

## Overview

The cost research agent now tracks:
- **Token usage** (input/output tokens per interaction)
- **Real dollar costs** (based on Gemini 2.5 Flash pricing)
- **Performance metrics** (duration, cache hits, searches)
- **Aggregate statistics** (averages across all interactions)

---

## Pricing (Gemini 2.5 Flash - January 2025)

| Type | Cost per 1M Tokens | Notes |
|------|-------------------|-------|
| Input tokens | $0.075 | Prompts up to 128k context |
| Output tokens | $0.30 | Generated text |
| Cached input | $0.01875 | 75% discount on cached content |

**Source:** https://ai.google.dev/pricing

---

## Automatic Tracking

Token usage is automatically tracked for every cost research query:

```python
from travel_concierge.sub_agents.cost_research.agent import cost_research_agent

# Run cost research (tokens tracked automatically)
result = await cost_research_agent.run_async(
    prompt="Research costs for Bangkok, 7 days, mid-range, 2 people",
    context=session_state
)
```

### What Gets Logged

After each research query completes, you'll see:

```
ğŸ’° Cost Research Complete | Bangkok, Thailand | â±ï¸ 18.3s |
ğŸ”¢ 12,456 tokens | ğŸ’µ $0.0042 | ğŸ” 4 searches @ $0.0011 each |
ğŸ“Š 50% cache hits
```

**Breakdown:**
- **Duration:** 18.3 seconds
- **Tokens:** 12,456 total (8,234 input + 4,222 output)
- **Cost:** $0.0042 USD
- **Searches:** 4 searches, ~$0.0011 per search
- **Cache:** 50% cache hit rate

---

## Viewing Statistics

### 1. In Application Logs

Token usage is automatically logged to the application logger:

```bash
# Set log level to INFO
export LOG_LEVEL=INFO

# Run your agent
python api_server.py
```

Watch for logs like:
```
INFO - ğŸ’° Cost Research Complete | Sydney, Australia | ...
INFO - âš¡ Performance Stats: avg=19.2s, min=15.1s, max=23.4s (n=5)
```

### 2. Using the Stats Script

Run the dedicated stats viewer:

```bash
cd python/agents/travel-concierge
python scripts/view_token_stats.py
```

**Output:**
```
================================================================================
ğŸ“Š COST RESEARCH TOKEN USAGE & COST ANALYSIS
================================================================================

Total Destinations Researched: 12

ğŸ’° COSTS:
  Total Cost: $0.0487
  Avg per Destination: $0.0041

ğŸ”¢ TOKENS:
  Total Tokens: 147,834
    - Input Tokens: 98,223
    - Output Tokens: 49,611
  Avg per Destination: 12,320 tokens

â±ï¸ PERFORMANCE:
  Avg Duration: 18.7s per destination

ğŸ’¡ PROJECTIONS:
  10 destinations: $0.04
  50 destinations: $0.20
  100 destinations: $0.41

ğŸ“‹ RECENT INTERACTIONS:
--------------------------------------------------------------------------------
1. Bangkok, Thailand
   â±ï¸ 18.3s | ğŸ”¢ 12,456 tokens | ğŸ’µ $0.0042 | ğŸ” 4 searches
2. Tokyo, Japan
   â±ï¸ 21.1s | ğŸ”¢ 14,332 tokens | ğŸ’µ $0.0048 | ğŸ” 4 searches
...
```

### 3. Programmatic Access

Access stats in your code:

```python
from travel_concierge.tools.token_tracker import get_tracker

tracker = get_tracker()

# Get aggregate stats
stats = tracker.get_aggregate_stats()
print(f"Total cost: ${stats['total_cost_usd']:.4f}")
print(f"Avg tokens: {stats['avg_tokens_per_destination']:,}")

# Access individual interactions
for interaction in tracker.interactions:
    print(f"{interaction.destination_name}: ${interaction.cost_usd:.4f}")
```

---

## Cost Estimation

Estimate costs before making queries:

```python
from travel_concierge.tools.token_tracker import estimate_cost

# Estimate for typical cost research query
# (based on observed averages: ~8,000 input + 4,000 output)
cost = estimate_cost(input_tokens=8000, output_tokens=4000)
print(f"Estimated cost: ${cost:.4f}")  # ~$0.0018
```

---

## Typical Token Usage

Based on real-world observations:

### Single Destination Research

| Metric | Typical Range | Notes |
|--------|--------------|-------|
| Input tokens | 6,000 - 10,000 | Prompt + search results |
| Output tokens | 3,000 - 5,000 | Structured JSON response |
| Total tokens | 9,000 - 15,000 | Varies by destination complexity |
| **Cost** | **$0.0015 - $0.0045** | Most common: ~$0.0025 |
| Duration | 15-30s | Without caching |
| Duration (cached) | 2-5s | With 50%+ cache hits |

### Multiple Destinations

For 10 destinations:
- **Total tokens:** ~120,000
- **Total cost:** ~$0.025
- **Duration:** ~3-5 minutes (without caching)
- **Duration (cached):** ~1-2 minutes (with caching)

---

## Optimizing Costs

### 1. Leverage Caching

The agent automatically caches search results for 1 hour:

```python
# First research: Fresh searches, full cost
cost1 = await research_destination("Bangkok")  # $0.0042

# Second research within 1 hour: Cached results, 95% cheaper
cost2 = await research_destination("Bangkok")  # $0.0002
```

**Savings:** ~95% on repeated queries

### 2. Batch Research

Research multiple destinations in one session to take advantage of warm caches:

```python
destinations = ["Bangkok", "Tokyo", "Sydney", "Paris"]

for dest in destinations:
    result = await research_destination(dest)
    # Common source sites (Numbeo, Booking.com) get cached
    # Later destinations benefit from earlier cache entries
```

### 3. Monitor Usage

Check aggregate stats regularly:

```bash
# Every 5 interactions, aggregate stats are logged
# Watch for cost trends and optimization opportunities
```

---

## Real-World Cost Examples

### Light Usage (10 destinations/month)
- **Tokens:** ~120,000
- **Cost:** ~$0.025/month
- **Annual:** ~$0.30/year

### Medium Usage (50 destinations/month)
- **Tokens:** ~600,000
- **Cost:** ~$0.12/month
- **Annual:** ~$1.50/year

### Heavy Usage (200 destinations/month)
- **Tokens:** ~2.4M
- **Cost:** ~$0.50/month
- **Annual:** ~$6/year

**With 50% caching:**
- Costs reduced by ~40-50%
- Heavy usage: ~$3-4/year

---

## Understanding the Logs

### Per-Interaction Log
```
ğŸ’° Cost Research Complete | Bangkok, Thailand | â±ï¸ 18.3s |
ğŸ”¢ 12,456 tokens | ğŸ’µ $0.0042 | ğŸ” 4 searches @ $0.0011 each |
ğŸ“Š 50% cache hits
```

- **ğŸ’°** Cost Research Complete
- **Destination:** Bangkok, Thailand
- **â±ï¸ Duration:** 18.3 seconds
- **ğŸ”¢ Tokens:** 12,456 total
- **ğŸ’µ Cost:** $0.0042 USD
- **ğŸ” Searches:** 4 searches, $0.0011 per search
- **ğŸ“Š Cache:** 50% cache hit rate

### Aggregate Stats Log
```
================================================================================
ğŸ“Š COST RESEARCH AGGREGATE STATS
================================================================================
Total Destinations Researched: 12
Total Cost: $0.0487
Total Tokens: 147,834
  - Input: 98,223
  - Output: 49,611
Average per Destination:
  - Cost: $0.0041
  - Duration: 18.7s
  - Tokens: 12,320
================================================================================
```

Logged every 5 interactions to track trends.

---

## Token Breakdown

### What Counts as Input Tokens?
- System prompt (research instructions)
- User request
- Conversation history
- Search results from google_search_grounding
- Tool responses

### What Counts as Output Tokens?
- Agent's reasoning
- Search queries generated
- Structured JSON output
- Confirmation messages

---

## API Response

Token usage is also available in agent responses:

```python
result = await cost_research_agent.run_async(...)

# Check final state for token usage
if hasattr(result, 'metadata'):
    usage = result.metadata.get('token_usage', {})
    print(f"Input: {usage.get('input_tokens', 0)}")
    print(f"Output: {usage.get('output_tokens', 0)}")
```

---

## Troubleshooting

### "No cost research interactions tracked yet"

**Cause:** No queries have completed since the tracker was initialized.

**Solution:**
1. Run a cost research query
2. Wait for completion
3. Check logs or run `scripts/view_token_stats.py`

### Token counts seem low

**Cause:** Token tracking extracts from `usage_metadata` which may not be available in all ADK versions.

**Solution:** Update to latest Google ADK version:
```bash
pip install --upgrade google-genai
```

### Costs don't match expectations

**Verification:**
1. Check Gemini 2.5 Flash pricing: https://ai.google.dev/pricing
2. Verify token counts in logs
3. Calculate manually:
   ```
   cost = (input_tokens / 1_000_000) * $0.075 +
          (output_tokens / 1_000_000) * $0.30
   ```

---

## Future Enhancements

Planned improvements:
1. **Persistent tracking** - Store stats in database
2. **Cost alerts** - Notify when daily/monthly budgets exceeded
3. **Per-user tracking** - Track costs by user/session
4. **Cost attribution** - Break down costs by search type
5. **Budget controls** - Prevent queries when budget exhausted

---

## Summary

Token tracking provides complete visibility into:
- **Cost per query** (~$0.0025 typical)
- **Token usage breakdown** (input/output)
- **Performance metrics** (duration, cache hits)
- **Aggregate trends** (averages, totals)

**Bottom line:** Cost research is very affordable at ~$0.0025 per destination with caching, or ~$0.30-$1.50/year for typical usage.
